\documentclass{article}
\usepackage{amsmath,amssymb}
\usepackage{bm}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[latin1]{inputenc}
\usepackage{units}

% paragraph layout
\setlength{\parindent}{0pt}
\setlength{\parskip}{2ex plus 0.8ex minus 0.5ex}

% derivatives
\newcommand{\dd}[2]{\frac{d #1}{d #2}}

\newcommand{\for}[0]{\quad \text{ for } \quad}
\newcommand{\xli}[0]{x_{i-1/2}}
\newcommand{\xri}[0]{x_{i+1/2}}
\newcommand{\xlj}[0]{x_{j-1/2}}
\newcommand{\xrj}[0]{x_{j+1/2}}
\newcommand{\fli}[0]{f_{i-1/2}}
\newcommand{\fri}[0]{f_{i+1/2}}

\numberwithin{equation}{section}

% XXX: indexing conventions?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% title page

\begin{document}

\title{Weighted essentially non-oscillatory schemes}
\author{Matthew Emmett}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% introduction

\section{Introduction}

We follow C.W. Shu in ``Essentially Non-oscillatory and Weighted
Essentially Non-oscillatory Schemes for Hyperbolic Conservation Laws''
(NASA/CR-97-206253, ICASE report no. 97-65).

Weighted esstentially non-oscillatory (WENO) techniques have many
applications.  We will focus our attention on one-dimensional
hyperbolic conservation law of the form
\begin{gather}
  \label{eq:pdecons}
  q_t + \bigl( f(q) \bigr)_x = 0.
\end{gather}
Finite-volume schemes do not solve \eqref{eq:pdecons} directly.  They
solve its integrated version instead.  Integrating \eqref{eq:pdecons}
over the interval $[a,b]$ we obtain
\begin{equation*}
  \dd{}{t} \overline{q}(t)
    + \frac{1}{b - a} \Bigl( f\bigl(q(b,t)\bigr)
                                - f\bigl(q(a,t)\bigr) \Bigr) = 0
\end{equation*}
where
\begin{equation*}
  \overline{q}(t)
    \equiv \frac{1}{b - a} \int_{a}^{b} q(\xi,t) \;d\xi
\end{equation*}
is the average value of $q$ over $[a,b]$.  This leads us to one of
the central problems in implementing a numerical scheme to solve
\eqref{eq:pdecons}: obtaining the values of $q$ at the boundaries $a$
and $b$ based on the average $\overline{q}$ of $q$.  This is the
\emph{reconstruction} problem.

\newpage
\section{Grid}

We consider a grid over the interval $[a,b]$ with $N$ cells.  We
denote the $N+1$ cell boundaries by
\begin{equation}
  x_{i-1/2} \for i = 1,\ldots,N+1
\end{equation}
so that
\begin{equation}
  a = x_{1/2} < x_{3/2} < \cdots < x_{N-1/2} < x_{N+1/2} = b.
\end{equation}
Subsequently, we denote the $N$ cells by
\begin{equation}
  C_i = [\xli, \xri] \for i=1,\ldots,N;
\end{equation}
the $N$ cell centres by
\begin{equation}
  x_i = \frac{\xli + \xri}{2} \for i=1,\ldots,N;
\end{equation}
the $N$ cell sizes by
\begin{equation}
  \Delta x_i = \xri - \xli \for i=1,\ldots,N;
\end{equation}
and the maximum cell size by
\begin{equation}
  \Delta x = \max_{i=1,\ldots,N} \Delta x_i.
\end{equation}

We denote the contiguous stencil around the cell $C_i$, containing $k$
cells shifted to the left by $r$ cells, by
\begin{equation}
  S_i^{r,k} = C_{i-r} \cup \cdots \cup C_{i-r+k-1}.
\end{equation}
Note that $S_i^{r,k}$ spans $k$ cells and contains $k+1$ cell
boundaries.

\newpage
\section{One dimensional reconstruction for smooth functions}
\label{sec:reconstruction}

Given the cell averages $\overline{f}_j$ of a function $f$ where
\begin{equation}
  \overline{f}_j = \frac{1}{\Delta x_j} \int_{\xlj}^{\xrj} f(\xi) \;d\xi
\end{equation}
we wish to find approximations to the function $f$ at various points
within each cell.  In particular, we might be interested in
approximating the function at the left cell boundary $\xli$, the right
cell boundary $\xri$, or at any point $\xi$ within the cell $C_i$.  If
the approximations are computed using $k$ cell averages, they should
be $k$-order accruate.  The remainder of this section will be devoted
to finding these approximations and showing that they are $k$-order
accuarate.  As it turns out, we will show that there are constants
$c_j$ (hereafter called \emph{reconstruction coefficients}) such that
the reconstructed values are given by
\begin{equation*}
  f(\xi) \approx \sum_{j=0}^{k-1} c_j\; \overline{f}_{i-r+j}.
\end{equation*}
That is, given a stencil $S_i^{r,k}$ that spans the $k$ cells
$C_{i-r},\ldots,C_{i-r+k-1}$, the reconstructed value of the original
function at some point $\xi$ in $C_i$ can be obtained using the cell
averages $\overline{f}_{j}$ over the cells $C_j$ in the stencil
$S_i^{r,k}$.  In general, the reconstruction coefficients $c_j$ depend
on the reconstruction point $\xi$, order $k$, left shift $r$, and cell
$C_i$, but \emph{not} on the function $f$.

In order to obtain the reconstruction coefficients $c_j$ and prove
accuracy, we will find polynomials $p^r_i$ of degree at most $k-1$
such that each $p^r_i$ is a $k$-order accurate approximation to $f$
inside $C_i$.  That is, given the cell averages $\overline{f}_j$, we
will find polynomials $p^r_i$ such that
\begin{equation*}
  p^r_i(x) = f(x) + O(\Delta x^k) \for x \in C_i.
\end{equation*}

In order to find these polynomials, we consider the function
\begin{equation}
  \label{eq:V}
  V(x) = \int_a^x f(\xi) \;d\xi.
\end{equation}
Using the cell averages $\overline{f}_j$ we can compute $V$ at the
cell boundaries $\xri$ through
\begin{align}
  V(\xri) &= \int_a^{\xri} f(\xi) \;d\xi \nonumber \\
          &= \sum_{j=1}^i \int_{\xlj}^{\xrj} f(\xi) \;d\xi \nonumber \\
          &= \sum_{j=1}^i \overline{f}_j \Delta x_j.
          \label{eq:Vsum}
\end{align}

Focusing on a particular cell $C_i$ and stencil $S_i^{r,k}$, the
unique polynomial $P^r_i$ of order $k$ which interpolates $V$ at the
$k+1$ points
\begin{equation*}
  x_{i-r-1/2}, \ldots, x_{i-r+k-1/2}
\end{equation*}
is given by
\begin{equation}
  \label{eq:P}
  P^r_i(x) = \sum_{l=0}^{k} \Biggl(
    V(x_{i-r+l-1/2}) \prod_{m=0, m \neq l}^{k}
      \frac{(x - x_{i-r+m-1/2})}{(x_{i-r+l-1/2} - x_{i-r+m-1/2})}
    \Biggr).
\end{equation}
This is the interpolating polynomial of $V$ in Lagrange form.
It can be shown (see Appendix~\ref{app:lagrange}) that
\begin{equation*}
  P^r_i(x) = V(x) + O(\Delta x^{k+1}) \for x \in S_i^{r,k}.
\end{equation*}
Therefore, the derivative $p^r_i$ of $P^r_i$ satisfies
\begin{equation*}
  p^r_i(x) = \dd{}{x} P^r_i(x) = f(x) + O(\Delta x^k) \for x \in S_i^{r,k}
\end{equation*}
and $p^r_i$ is of order $k-1$.

Furthermore, the cell averages of $p^r_i$ over the cells $C_j$ that
comprise the stencil $S_i^{r,k}$ satisfy
\begin{align*}
  \frac{1}{\Delta x_j} \int_{\xlj}^{\xrj} p^r_i(\xi) \;d\xi
    &= \frac{1}{\Delta x_j} \int_{\xlj}^{\xrj} P'_i(\xi) \;d\xi \\
    &= \frac{1}{\Delta x_j} \biggl( P^r_i(\xrj) - P^r_i(\xlj) \biggr) \\
    &= \frac{1}{\Delta x_j} \biggl( V(\xrj) - V(\xlj) \biggr) \\
    &= \frac{1}{\Delta x_j} \biggl( \int_a^{\xrj} f(\xi) \;d\xi
      - \int_a^{\xlj} f(\xi) \;d\xi \biggr) \\
    &= \frac{1}{\Delta x_j} \biggl(
      \int_{\xlj}^{\xrj} f(\xi) \;d\xi \biggr) \\
    &= \overline{f}_j \for j=i-r,\ldots,i-r+k-1.
\end{align*}
That is, the cell averages of the approximating polynomials $p^r_i$
match the cell averages the original function in each of the cells
$C_j$ which comprise the stencil $S_i^{r,k}$.

So far we have constructed polynomials $p^r_i$ that approximate the
original function $f$ on the stencils $S_{i}^{r,k}$ to $k$-order using
only the cell averages $\overline{f}_j$ for $j=i-r,\ldots,i-r+k-1$.

Now we consider the practical problem of finding the constants $c_j$.
Subtracting $V(x_{i-r-1/2})$ from $P^r_i(x)$ and using
\begin{equation*}
  \sum_{l=0}^{k} \prod_{m=0, m \neq l}^{k}
    \frac{(x - x_{i-r+m-1/2})}{(x_{i-r+l-1/2} - x_{i-r+m-1/2})} = 1
  \quad \text{ and } \quad
  V(x_{i-r+l-1/2}) - V(x_{i-r-1/2}) \equiv 0 \text{ for } l = 0
\end{equation*}
we obtain
\begin{equation*}
  P^r_i(x) - V(x_{i-r-1/2}) = \sum_{l=1}^{k} \Biggl(
    \bigl( V(x_{i-r+l-1/2}) - V(x_{i-r-1/2}) \bigr)
    \prod_{m=0, m \neq l}^{k}
      \frac{(x - x_{i-r+m-1/2})}{(x_{i-r+l-1/2} - x_{i-r+m-1/2})}
      \Biggr).
\end{equation*}
Taking the derivative of the above, we obtain
\begin{equation*}
  \dd{}{x}P^r_i(x) = \dd{}{x} \Biggl[ \sum_{l=1}^{k} \Biggl(
    \bigl( V(x_{i-r+l-1/2}) - V(x_{i-r-1/2}) \bigr) \prod_{m=0, m \neq l}^{k}
      \frac{(x - x_{i-r+m-1/2})}{(x_{i-r+l-1/2} - x_{i-r+m-1/2})}
      \Biggr) \Biggr]
\end{equation*}
and hence
\begin{equation}
  p^r_i(x) = \sum_{l=1}^{k} \Biggl(
  \bigl( V(x_{i-r+l-1/2}) - V(x_{i-r-1/2}) \bigr) \
    \frac{\sum_{m=0, m \neq l}^{k} \prod_{n=0, n \neq l,m}^{k}
      (x - x_{i-r+n-1/2})}{\prod_{m=0, m \neq l}^{k}
      (x_{i-r+l-1/2} - x_{i-r+m-1/2})} \Biggr). \label{eq:pV}
\end{equation}
Employing \eqref{eq:Vsum}, we obtain
\begin{equation}
  p^r_i(x) = \sum_{l=1}^{k} \Biggl(
  \biggl( \sum_{j=0}^{l-1} \overline{f}_{i-r+j} \Delta x_{i-r+j} \biggr)
  \frac{\sum_{m=0, m \neq l}^{k} \prod_{n=0, n \neq l,m}^{k}
    (x - x_{i-r+n-1/2})}{\prod_{m=0, m \neq l}^{k}
    (x_{i-r+l-1/2} - x_{i-r+m-1/2})} \Biggr).
\end{equation}
Rearranging, we obtain
\begin{equation*}
  p^r_i(\xri) = \sum_{j=0}^{k-1} \sum_{l=j+1}^k
  \frac{\sum_{m=0, m \neq l}^{k} \prod_{n=0, n \neq l,m}^{k}
    (x - x_{i-r+n-1/2})}{\prod_{m=0, m \neq l}^{k}
    (x_{i-r+l-1/2} - x_{i-r+m-1/2})} \ \Delta x_{i-r+j} \overline{v}_{i-r+j}.
\end{equation*}
Therefore, the reconstruction coefficients $c_j$ used to reconstruct
the function $f$ at the point $\xi$ are given by
\begin{equation}
  c_j = \sum_{l=j+1}^k \frac{\sum_{m=0, m \neq l}^{k}
    \prod_{n=0, n \neq l,m}^{k} (\xi - x_{i-r+n-1/2})}{
    \prod_{m=0, m \neq l}^{k} (x_{i-r+l-1/2} - x_{i-r+m-1/2})}
    \ \Delta x_{i-r+j}.
\end{equation}
Note that the the reconstruction coefficients $c_j$ depend on $\xi$,
$i$, $r$, and $k$.

\subsection{Further derivatives}

In order to approximate the first derivative of the original function
$f$ we consider the first derivative of $p^r_i(x)$.  We obtain
\begin{align*}
  \dd{}{x} p^r_i(x) &= \dd{}{x} \Biggl[ \sum_{l=1}^{k} \Biggl(
  \bigl( V(x_{i-r+l-1/2}) - V(x_{i-r-1/2}) \bigr) \
    \frac{\sum_{m=0, m \neq l}^{k} \prod_{n=0, n \neq l,m}^{k}
      (x - x_{i-r+n-1/2})}{\prod_{m=0, m \neq l}^{k}
      (x_{i-r+l-1/2} - x_{i-r+m-1/2})} \Biggr) \Biggr] \\
    &= \sum_{l=1}^{k} \Biggl(
    \bigl( V(x_{i-r+l-1/2}) - V(x_{i-r-1/2}) \bigr) \
    \frac{\sum_{m=0, m \neq l}^{k} \sum_{n=0, n \neq l,m}^{k} \prod_{p=0, p \neq l, m, n}
      (x - x_{i-r+p-1/2})}{\prod_{m=0, m \neq l}^{k}
      (x_{i-r+l-1/2} - x_{i-r+m-1/2})} \Biggr).
\end{align*}
Employing \eqref{eq:Vsum}, we obtain
\begin{equation*}
  \dd{}{x} p^r_i(x) = \sum_{l=1}^{k} \Biggl(
  \biggl( \sum_{j=0}^{l-1} \overline{v}_{i-r+j} \Delta x_{i-r+j} \biggr)
  \frac{\sum_{m=0, m \neq l}^{k} \sum_{n=0, n \neq l,m}^{k} \prod_{p=0, p \neq l, m, n}
    (x - x_{i-r+p-1/2})}{\prod_{m=0, m \neq l}^{k}
    (x_{i-r+l-1/2} - x_{i-r+m-1/2})} \Biggr).
\end{equation*}
Rearranging, we obtain
\begin{equation*}
  \dd{}{x} p^r_i(x) = \sum_{j=0}^{k-1} \sum_{l=j+1}^k
  \frac{\sum_{m=0, m \neq l}^{k} \sum_{n=0, n \neq l,m}^{k} \prod_{p=0, p \neq l, m, n}
    (x - x_{i-r+p-1/2})}{\prod_{m=0, m \neq l}^{k}
    (x_{i-r+l-1/2} - x_{i-r+m-1/2})}
  \ \Delta x_{i-r+j} \overline{v}_{i-r+j}.
\end{equation*}
Therefore, the reconstruction coefficients for the first derivative
are
\begin{equation*}
  c_j = \sum_{l=j+1}^k
  \frac{\sum_{m=0, m \neq l}^{k} \sum_{n=0, n \neq l,m}^{k} \prod_{p=0, p \neq l, m, n}
    (\xi - x_{i-r+p-1/2})}{\prod_{m=0, m \neq l}^{k}
    (x_{i-r+l-1/2} - x_{i-r+m-1/2})}
  \ \Delta x_{i-r+j}
\end{equation*}

\subsection{Summary}

In summary, given a stencil $S_i^{r,k}$ and the cell averages
$\overline{f}_j$ of a function $f$, we can reconstruct $f$ at any
point $\xi$ in the cell $C_i$ according to
\begin{equation}
  \label{eq:sumvri}
  f(\xi) \approx \sum_{j=0}^{k-1} c_j\; \overline{f}_{i-r+j}
\end{equation}
where
\begin{equation}
  c_j = \sum_{l=j+1}^k \frac{\sum_{m=0, m \neq l}^{k}
    \prod_{n=0, n \neq l,m}^{k} (\xi - x_{i-r+n-1/2})}{
    \prod_{m=0, m \neq l}^{k} (x_{i-r+l-1/2} - x_{i-r+m-1/2})}
  \ \Delta x_{i-r+j}.
\end{equation}
Furthermore, the approximation is accurate to order $k$ so that
\begin{equation*}
  \sum_{j=0}^{k-1} c_j\; \overline{f}_{i-r+j} = f(\xi) + O(\Delta x^k)
\end{equation*}
where
\begin{equation*}
  \Delta x = \max_{j=i-r,\ldots,i-r+k-1} \Delta x_j.
\end{equation*}
The permissable values of left shift parameter $r$ in
\eqref{eq:sumvri} are $-1,\ldots,k-1$ so that the results of
Appendix~\ref{app:lagrange} hold.

\newpage
\section{One dimensional reconstruction for piece-wise smooth functions}

The solutions of hyperbolic conservation laws may contain
discontinuities, and therefore we are interested in reconstructing
piecewise smooth functions.  A piecewise smooth function $f$ is smooth
except at finitely many isolated points.  At these points, $f$ and its
derivatives (at least up to the order of the scheme) are assumed to
have finite left and right limits.

For such piecewise smooth functions, the order of accuracy herein
referred to is formal.  That is, it is defined as the accuracy
determined by the local error in the smooth regions of the function.

The basic idea of WENO is to use a convex combination of several
stencils to form the reconstruction of $f$, and, if a stencil contains
a discontinuity, its weight should be close to zero.  In smooth
regions, using several stencils will also serve to increase the order
of accuracy.

Consider the $k$ stencils
\begin{equation*}
  S_i^{r,k} \for r=0,\ldots,k-1
\end{equation*}
that can be used to reconstruct the value of $f$ at some point $\xi$
in the cell $C_i$.  These stencils span $2k-1$ cells.  We denote the
$k$ different reconstructions by
\begin{equation}
  \label{eq:fr}
  f(\xi) \approx f^r = \sum_{j=0}^{k-1}\; c^r_j \bar{v}_{i-r+j} \for r=0,\dots,k-1
\end{equation}
where we have added the superscript $r$ to the function $f$ and the
reconstruction coefficients $c_j$ to make their dependance on the left
shift $r$ explicit.

A WENO reconstruction takes a convex combination of all $f^r$ defined
in \eqref{eq:fr} as a new approximation according to
\begin{equation}
  \label{eq:fweno}
  f(\xi) \approx \sum_{r=0}^{k-1} \omega_i^r f^r
\end{equation}
where we require
\begin{equation}
  \omega_i^r \geq 0 \quad \text{ and } \quad \sum_{r=0}^{k-1} \omega_i^r = 1.
\end{equation}

In smooth regions where all $k$ stencils that can be used to
reconstruct $f(\xi)$ in \eqref{eq:fr} do not contain discontinuities,
we could reconstruct $f(\xi)$ to order $2k-1$ using the stencil
$S_i^{k-1,2k-1}$ to obtain
\begin{equation}
  \label{eq:fopt}
  f(\xi) = \sum_{j=0}^{2k-2} c_j^*\, \bar{f}_{i-(k-1)+j}
\end{equation}
where we have added the superscript $*$ to the reconstruction
coefficients $c_j$ to highlight that they are optimal (ie, higher
order).  Combining \eqref{eq:fr}, \eqref{eq:fweno}, and
\eqref{eq:fopt}, we obtain
\begin{equation}
  \label{eq:fopt2}
  \sum_{j=0}^{2k-2} c_j^*\, \bar{f}_{i-(k-1)+j}
    = \sum_{r=0}^{k-1} \omega_i^r \left( \sum_{l=0}^{k-1} c_l^r\, \bar{f}_{i-r+l} \right).
\end{equation}
Rearranging, we obtain
\begin{equation*}
  \sum_{j=0}^{2k-2} c_j^*\, \bar{f}_{i-(k-1)+j}
    = \sum_{j=0}^{2k-2} \left(
      \sum_{l=\max(0,j-k+1)}^{\min(k-1,j)} \omega_i^{k-(j+1)+l} c_l^{k-(j+1)+l}
    \right) \bar{f}_{i-(k-1)+j}.
\end{equation*}
\newpage
Therefore, we have $2k-1$ equations
\begin{gather}
  \label{eq:omegasys}
  \sum_{l=\max(0,j-k+1)}^{\min(k-1,j)} \omega_i^{k-(j+1)+l} c_l^{k-(j+1)+l} = c_j^*
    \for j = 0,\ldots,2k-2
\end{gather}
at each $i$ (and $\xi$) for the weights $\omega_i^r$.  For
unstructured grids the systems \eqref{eq:omegasys} are
over-determined, and therefore we must use some kind of optimisation
algorithm in order to find the weights $\omega_i^r$.  For structured
grids the systems \eqref{eq:omegasys} are no longer over-determined,
and the weights $\omega_i^r$ can be found explicity (and are
independent of $i$).

The weights $\omega_i^r$ defined by \eqref{eq:fopt2} and determined by
\eqref{eq:omegasys} are called \emph{optimal weights} since they can
be used to reconstruct a function to order $2k-1$ in regions where the
function is smooth.  We will henceforth denote the optimal weights by
$\varpi_i^r$.

We now consider the practical problem of choosing the weights
$\omega_i^r$.  If we choose the weights $\omega_i^r$ sufficiently
close to the optimal weights $\varpi_i^r$ in regions where the
function is smooth, then we can achieve $2k-1$ order accuracy.  In
order to determine how close to the optimal weights $\varpi_i^r$ the
weights $\omega_i^r$ must be choosen we consider the reconstruction
\begin{equation}
  \label{eq:omegacloseeqn}
  f(\xi) \approx \sum_{r=0}^{k-1} \omega_i^r f^r
    = \sum_{r=0}^{k-1} \varpi_i^r f^r
    + \sum_{r=0}^{k-1} \bigl( \omega_i^r - \varpi_i^r \bigr) f^r.
\end{equation}
If we choose
\begin{equation}
  \label{eq:omegaclose}
  \omega_i^r = \varpi_i^r + O(\Delta x^{k-1})
\end{equation}
then each term in the last summation of \eqref{eq:omegaclose} becomes
$O(\Delta x^{2k-1})$ and therefore $2k-1$ order accuracy is preserved
by the reconstruction.

If we define
\begin{equation}
  \label{eq:omega}
  \omega_i^r = \frac{\alpha_i^r}{\alpha_i^0 + \cdots + \alpha_i^{k-1}}
\end{equation}
where
\begin{equation}
  \label{eq:alpha}
  \alpha_i^r = \frac{\varpi_i^r}{(\epsilon + \sigma_i^r)^p} \for r = 0, \ldots, k-1;
\end{equation}
and $\epsilon$ is a positive real number used to avoid dividing by
zero (usually $\epsilon = 10^{-6}$), $p$ is some power (usually 2),
and $\sigma_i^r$ is a measure of the smoothness of the function $v$ in
the stencil $S^{r,k}_i$; with the smoothnesses $\sigma_i^r$ chosen
appropriately, then \eqref{eq:omegaclose} is satisfied.

Typically, the smoothness measurement presented by Jiang and Shu is
used.  They define the smoothness according to
\begin{equation}
  \label{eq:sigma}
  \sigma_i^r = \sum_{l=1}^{k-1} \int_{\xlj}^{\xrj} (\Delta x_j)^{2l-1} \left( \frac{d^l}{dx^l} p_i^r(x)  \right)^2 \;dx
\end{equation}
which is the sum of the $L^2$ norms of the derivatives of the
approximating polynomial.

\newpage
\subsection{One-sided (up/down wind) reconstructions}

In some situations we may need to impose that some cells be excluded
from the reconstruction process.  For example, at the front of a
dam-break flow with a positive front velocity there is a wet-dry
interface and the dry cells to the right of the front should be
avoided.

A \emph{left-biased} WENO reconstruction is one in which the weights
\begin{equation*}
  \omega_i^r=0 \quad \text{ for } \quad r < s
\end{equation*}
where $s>0$ is some parameter that controls how many cells are
excluded from the reconstruction \eqref{eq:fweno}.  Intuitively, $s$
is also the number of cells to exlude from the right.

A \emph{right-biased} WENO reconstruction is one in which the weights
\begin{equation*}
  \omega_i^r=0 \quad \text{ for } \quad r > k - |s| - 1
\end{equation*}
where $s<0$ is some parameter that controls how many cells are
excluded from the reconstruction \eqref{eq:fweno}.  Intuitively, $|s|$
is also the number of cell to exclude from the left.

That is, if $s > 0$ the WENO reconstruction will be left-biased and
reconstructions with $r < s$ will be ignored; if $s<0$ the WENO
reconstruction will be right-biased and reconstructions with $r > k -
|s| - 1$ will be ignored.  Once again, we need to determine optimal
weights for both left- and right-biased reconstructions.

For left-biased reconstructions ($s > 0$), we reconstruct $f(\xi)$ to
order $2k - s - 1$ using the stencil $S_i^{k-1,\; 2k-s-1}$ to obtain the
optimal reconstruction coefficients $c^*_j$ (similar to
\eqref{eq:fopt}).  Therefore, similar to \eqref{eq:omegasys}, we have
$2k-s-1$ equations
\begin{equation}
  \label{eq:left_omegasys}
  \sum_{l=\max(0,j-k+s+1)}^{\min(k-1,j)} \omega_i^{k-(j+1)+l} c_l^{k-(j+1)+l} = c_j^*
    \for j = 0,\ldots,2k-s-2.
\end{equation}

For right-biased reconstructions ($s < 0$), we reconstruct $f(\xi)$ to
order $2k - |s| - 1$ using the stencil $S_i^{k-|s|-1,\; 2k-|s|-1}$ to obtain the
optimal reconstruction coefficients $c^*_j$ (similar to
\eqref{eq:fopt}).  Therefore, similar to \eqref{eq:omegasys}, we have
$2k-|s|-1$ equations
\begin{equation}
  \label{eq:right_omegasys}
  \sum_{l=\max(0,j-k+|s|+1)}^{\min(k-1,j)} \omega_i^{k-(j+1)+l} c_l^{k+s-(j+1)+l} = c_j^*
    \for j = 0,\ldots,2k-|s|-2.
\end{equation}

%%
%% appendix
%%

\newpage
\appendix
\section{Error of Lagrange interpolating polynomials}
\label{app:lagrange}

Let $f(x) \in C^{n}([a,b])$, and $p(x)$ be the interpolating
polynomial of degree $n-1$ such that
\begin{equation}
  p(x_i) = f(x_i) \for i=1,\ldots,n
\end{equation}
where
\begin{equation}
  a = x_1 < x_2 < \cdots < x_{n-1} < x_n = b.
\end{equation}
Then
\begin{equation}
  p(x) = f(x) + O(\Delta x^n) \for x \in [a,b]
\end{equation}
where
\begin{equation}
  \Delta x = \max_{i=2,\ldots,n} x_i - x_{i-1}.
\end{equation}

\textbf{Proof.}  Let $x \in [a,b]$.  If $x = x_i$ for some
$i=1,\ldots,n$ then $f(x) - p(x) = 0$ since $p(x)$ is the
interpolating polynomial.  Otherwise, let
\begin{equation}
  \Phi(x) = \frac{f(x) - p(x)}{\prod_{i=1}^n (x - x_i)}
\end{equation}
and
\begin{equation}
  g(x,\xi) = f(\xi) - p(\xi) - \Phi(x) \prod_{i=1}^n (\xi - x_i).
\end{equation}
Then $g(x,\xi)$ is $n$ times differentiable with respect to $\xi$,
$g(x,x_i) = 0$ for $i=1,\ldots,n$, and $g(x,x) = 0$.  Applying Rolle's
theorem successively across all interpolation points $x_i$ and $x$ we
obtain
\begin{equation}
  \label{eq:xistar}
  \frac{\partial^n}{\partial \xi^n} g(x,\xi)\biggr|_{\xi=\xi^*} = 0
\end{equation}
for some $\xi^* \in (a,b)$.  Futhermore
\begin{equation}
  \label{eq:partials}
  \frac{\partial^n}{\partial \xi^n} g(x,\xi) = f^n(\xi) - n!\;\Phi(x)
\end{equation}
so that, combininig \eqref{eq:xistar} and \eqref{eq:partials}, we obtain
\begin{equation}
  \Phi(x) = \frac{f^n(\xi^*)}{n!}
\end{equation}
and therefore
\begin{equation}
  f(x) - p(x) = \frac{f^n(\xi^*)}{n!} \prod_{i=1}^n (x - x_i).
\end{equation}
Finally, we conclude that
\begin{equation}
  p(x) = f(x) + O(\Delta x^n).
\end{equation}
That is, if $p(x)$ interpolates $f(x)$ at $n$ points, then it is
accurate to $O(\Delta x^n)$ where $\Delta x$ is the maximum space
between the interpolating points.

\end{document}
